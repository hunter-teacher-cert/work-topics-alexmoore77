# -*- coding: utf-8 -*-
"""MiniLesson2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rIoemKxr_SHart22BnbMxjWTcSDLbXzn

# Mini Lesson 2 
We will be working with real data related to scanning times and attendance of a school.

*Instructions*  
*Step 1 - DOWNLOAD*:  Download the CSV file:  [scanTimes.csv](https://drive.google.com/file/d/198mq2U5ST2xVpRQkPVGHVfNYaL9vZWb9/view?usp=sharing), .  
*Step 2 - UPLOAD*:  Upload to the sample_data folder of Google Colab the three files you just downloaded:  scanTimes.csv.
"""

import pandas as pd
import sqlite3

def pd_to_sqlDB(input_df: pd.DataFrame,
                table_name: str,
                db_name: str = 'default.db') -> None:
    # Step 1: Setup local logging
    import logging
    logging.basicConfig(level=logging.INFO,
                        format='%(asctime)s %(levelname)s: %(message)s',
                        datefmt='%Y-%m-%d %H:%M:%S')

    # Step 2: Find columns in the dataframe
    cols = input_df.columns
    cols_string = ','.join(cols)
    val_wildcard_string = ','.join(['?'] * len(cols))

    # Step 3: Connect to a DB file if it exists, else crete a new file
    con = sqlite3.connect(db_name)
    cur = con.cursor()
    logging.info(f'SQL DB {db_name} created')

    # Step 4: Create Table
    sql_string = f"""CREATE TABLE {table_name} ({cols_string});"""
    cur.execute(sql_string)
    logging.info(f'SQL Table {table_name} created with {len(cols)} columns')

    # Step 5: Upload the dataframe
    rows_to_upload = input_df.to_dict(orient='split')['data']
    sql_string = f"""INSERT INTO {table_name} ({cols_string}) VALUES ({val_wildcard_string});"""
    cur.executemany(sql_string, rows_to_upload)
    logging.info(f'{len(rows_to_upload)} rows uploaded to {table_name}')
  
    # Step 6: Commit the changes and close the connection
    con.commit()
    con.close()


def sql_query_to_pd(sql_query_string: str, db_name: str ='default.db') -> pd.DataFrame:  
    # Step 1: Connect to the SQL DB
    con = sqlite3.connect(db_name)

    # Step 2: Execute the SQL query
    cursor = con.execute(sql_query_string)

    # Step 3: Fetch the data and column names
    result_data = cursor.fetchall()
    cols = [description[0] for description in cursor.description]

    # Step 4: Close the connection
    con.close()

    # Step 5: Return as a dataframe
    return pd.DataFrame(result_data, columns=cols)

#Scan TABLE
# Step 1: Read the csv file into a dataframe
input_df = pd.read_csv('sample_data/scanTimes.csv')
 
# Step 2: Upload the dataframe to a SQL Table
pd_to_sqlDB(input_df,
            table_name='Scan',
            db_name='default.db')

"""# ORDER BY
The ORDER BY keyword is used to sort the result-set in ascending or descending order.

Syntax:
```
SELECT column1, column2, ...
FROM table_name
ORDER BY column1, column2, ... ASC|DESC;
```

More on ORDER BY: [W3 Schools](https://www.w3schools.com/sql/sql_orderby.asp)

"""

#Select all rows from Scan table and Order By scantime
sql_query_string = """
    SELECT * 
    FROM Scan
    ORDER BY ScanTime ASC
"""
 
#Exectue the SQL query
result_df = sql_query_to_pd(sql_query_string, db_name='default.db')
result_df

#Select all rows from Scan table Where Status is Tardy and Order By scantime
sql_query_string = """
    SELECT * FROM Scan 
    WHERE Status = 'Tardy'
    ORDER BY ScanTime ASC
"""
 
#Exectue the SQL query
result_df = sql_query_to_pd(sql_query_string, db_name='default.db')
result_df

"""# COUNT(), AVG(), SUM()
These functions help you take the count, average or sum of a numerical column

COUNT Syntax:
```
SELECT COUNT(column_name)
FROM table_name
WHERE condition;
```
AVG Syntax:
```
SELECT AVG(column_name)
FROM table_name
WHERE condition;
```
SUM Syntax:
```
SELECT SUM(column_name)
FROM table_name
WHERE condition;
```
More on this: [W3 Schools](https://www.w3schools.com/sql/sql_count_avg_sum.asp)
"""

#Finding the total number of on times in our Scan table
sql_query_string = """
    SELECT COUNT(Status)
    FROM Scan
    WHERE Status = 'Present on time'
"""
 
#Exectue the SQL query
result_df = sql_query_to_pd(sql_query_string, db_name='default.db')
result_df

#TODO: Find the total number of tardies in our Scan table 
#PUT YOUR COMMENT HERE
sql_query_string = """
    SELECT COUNT(Status)
    FROM Scan
    WHERE Status = 'Tardy'
"""
 
#Exectue the SQL query
result_df = sql_query_to_pd(sql_query_string, db_name='default.db')
result_df

#TODO: Find the total number of 11th graders in our Scan table 
sql_query_string = """
    SELECT COUNT(Grade)
    FROM Scan
    WHERE Grade = 11 OR Grade = 12

"""
 
#Exectue the SQL query
result_df = sql_query_to_pd(sql_query_string, db_name='default.db')
result_df

#TODO: Find the total number of 11th graders in our Scan table whose last name starts with M
sql_query_string = """
    YOUR QUERY HERE
"""
 
#Exectue the SQL query
result_df = sql_query_to_pd(sql_query_string, db_name='default.db')
result_df

"""# GROUP BY
The GROUP BY statement groups rows that have the same values into summary rows, like "find the number of customers in each country".

The GROUP BY statement is often used with aggregate functions (COUNT(), MAX(), MIN(), SUM(), AVG()) to group the result-set by one or more columns.

Syntax:
```
SELECT column_name(s)
FROM table_name
WHERE condition
GROUP BY column_name(s)
ORDER BY column_name(s);
```

More on GROUP BY: [W3 Schools](https://www.w3schools.com/sql/sql_groupby.asp)
"""

#Organizing our Scan table into groups based on status
#By selecting the Status column in addition to 
#COUNT(Status), it lets us know which Group is related to
#which count
sql_query_string = """
    SELECT COUNT(Status), Status
    FROM Scan
    GROUP BY Status
"""
 
#Exectue the SQL query
result_df = sql_query_to_pd(sql_query_string, db_name='default.db')
result_df

#TODO: Select the records/rows from Scan table where students are Tardy and GROUP BY Grade
sql_query_string = """
    SELECT COUNT(Grade), Grade
    FROM Scan
    WHERE Status = 'Tardy'
    GROUP BY Grade
"""
 
#Exectue the SQL query
result_df = sql_query_to_pd(sql_query_string, db_name='default.db')
result_df